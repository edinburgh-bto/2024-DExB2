{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa410960",
   "metadata": {
    "papermill": {
     "duration": 0.033877,
     "end_time": "2023-03-07T07:11:25.148989",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.115112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122b8c2-cc1f-46fb-9847-6fca4c14c8d1",
   "metadata": {
    "papermill": {
     "duration": 0.033877,
     "end_time": "2023-03-07T07:11:25.148989",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.115112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a09f21",
   "metadata": {
    "papermill": {
     "duration": 0.028648,
     "end_time": "2023-03-07T07:11:25.207877",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.179229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Today we revisited some basic concepts of linear regression. We focused on multiple regression and variations of linear regression that can be useful. In this notebook, we will use and compare the different regression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296b785-434a-4762-b9da-1a66fb2bfe47",
   "metadata": {
    "papermill": {
     "duration": 0.028648,
     "end_time": "2023-03-07T07:11:25.207877",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.179229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will analyse a dataset of marine snails, abalone (https://en.wikipedia.org/wiki/Abalone). The dataset contains measurements of physical features of abalone, along with their **age measured in terms of the number of rings on their shells**. The columns in the dataset are:\n",
    "\n",
    "- **Sex**: This column indicates the sex of the abalone and is of object data type. There are three possible values: 'M' for male, 'F' for female, and 'I' for infant.\n",
    "\n",
    "- **Length**: This column contains the longest shell measurement in mm and is of float (continuous) data type.\n",
    "\n",
    "- **Diameter**: This column contains the measurement perpendicular to length in mm and is of float data type.\n",
    "\n",
    "- **Height**: This column contains the height of the whole abalone in mm and is of float data type.\n",
    "\n",
    "- **Whole weight**: This column contains the weight of the whole abalone in grams and is of float data type.\n",
    "\n",
    "- **Shucked weight**: This column contains the weight of the meat of the abalone in grams and is of float data type.\n",
    "\n",
    "- **Viscera weight**: This column contains the weight of the abalone's gut (after bleeding) in grams and is of float data type.\n",
    "\n",
    "- **Shell weight**: This column contains the weight of the abalone's shell after being dried in grams and is of float data type.\n",
    "\n",
    "- **Rings**: This column indicates the age of the abalone in terms of the number of rings on their shell, and is of integer data type.\n",
    "\n",
    "We aim to use these measurements to predict the age of abalone without the need to perform the tedious task of counting the rings through a microscope. By analyzing the relationship between these physical features and the age of abalone, we can build a predictive model to estimate their age, which can be useful for various applications in aquaculture, ecology, and fisheries management.\n",
    "\n",
    "![](https://images.unsplash.com/photo-1619968987472-4d1b2784592e?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebfe79-859e-4062-b293-a31feccc433b",
   "metadata": {
    "papermill": {
     "duration": 0.033877,
     "end_time": "2023-03-07T07:11:25.148989",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.115112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Import and preparation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836947f",
   "metadata": {
    "papermill": {
     "duration": 0.028356,
     "end_time": "2023-03-07T07:11:25.266838",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.238482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.1. Importing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef8592-15b6-4e39-a81e-f227cf272e00",
   "metadata": {
    "papermill": {
     "duration": 0.028356,
     "end_time": "2023-03-07T07:11:25.266838",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.238482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As usual, we start by importing libraries we will use later on. Throughout the notebook, if any functions are unclear, try googling the library and function to familiarize yourself with the functions and their in- and outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdecd8",
   "metadata": {
    "papermill": {
     "duration": 2.386122,
     "end_time": "2023-03-07T07:11:27.681462",
     "exception": false,
     "start_time": "2023-03-07T07:11:25.295340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62e6e2",
   "metadata": {
    "papermill": {
     "duration": 0.028696,
     "end_time": "2023-03-07T07:11:27.744969",
     "exception": false,
     "start_time": "2023-03-07T07:11:27.716273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.2. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064732e-3492-4a77-ada2-cfa0ca300246",
   "metadata": {
    "papermill": {
     "duration": 0.028696,
     "end_time": "2023-03-07T07:11:27.744969",
     "exception": false,
     "start_time": "2023-03-07T07:11:27.716273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Load the file ```abalone.csv``` located in the same directory as this notebook using ```read_csv()``` from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ef84c",
   "metadata": {
    "papermill": {
     "duration": 0.097739,
     "end_time": "2023-03-07T07:11:27.874421",
     "exception": false,
     "start_time": "2023-03-07T07:11:27.776682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d1feb-9bb9-4ebc-83e2-059b98c86384",
   "metadata": {
    "papermill": {
     "duration": 0.028696,
     "end_time": "2023-03-07T07:11:27.744969",
     "exception": false,
     "start_time": "2023-03-07T07:11:27.716273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.3. Data summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086f67c-32cc-4c33-85dd-43ce30ddc6e4",
   "metadata": {
    "papermill": {
     "duration": 0.028696,
     "end_time": "2023-03-07T07:11:27.744969",
     "exception": false,
     "start_time": "2023-03-07T07:11:27.716273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As usual, we start by having a peak at the data. \n",
    "\n",
    "**TASK:** Use ```head()``` and ```info()``` on the dataframe to get a first idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745b03e-cf0b-4c1e-84d6-9c94bc135458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ec0df",
   "metadata": {
    "papermill": {
     "duration": 0.058877,
     "end_time": "2023-03-07T07:11:27.971993",
     "exception": false,
     "start_time": "2023-03-07T07:11:27.913116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77ba1c42",
   "metadata": {
    "papermill": {
     "duration": 0.030686,
     "end_time": "2023-03-07T07:11:28.093363",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.062677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.4. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ab2c5-88d7-481b-a0d0-c2eb80f72745",
   "metadata": {
    "papermill": {
     "duration": 0.030686,
     "end_time": "2023-03-07T07:11:28.093363",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.062677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.4.1 Label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c29d24-5608-4835-a450-e055449490a8",
   "metadata": {
    "papermill": {
     "duration": 0.030686,
     "end_time": "2023-03-07T07:11:28.093363",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.062677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We first convert the categorical values in \"Sex\" into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33af2c",
   "metadata": {
    "papermill": {
     "duration": 0.040609,
     "end_time": "2023-03-07T07:11:28.166070",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.125461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Sex'] = le.fit_transform(df['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44c500-7773-4e2f-a8c2-ac7ffc0fbeec",
   "metadata": {
    "papermill": {
     "duration": 0.030686,
     "end_time": "2023-03-07T07:11:28.093363",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.062677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Use ```info()``` again to see how the label encoding has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30fbe9",
   "metadata": {
    "papermill": {
     "duration": 0.049285,
     "end_time": "2023-03-07T07:11:28.246224",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.196939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61dc32fd",
   "metadata": {
    "papermill": {
     "duration": 0.030678,
     "end_time": "2023-03-07T07:11:28.306817",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.276139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.4.2. Check for missing data\n",
    "\n",
    "Often, datasets are incomplete and contain ```NaN``` (not a number). Let's check if this is a problem here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e742e",
   "metadata": {
    "papermill": {
     "duration": 0.042453,
     "end_time": "2023-03-07T07:11:28.379408",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.336955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe2715-aafd-4b5c-a944-0b616ce1e315",
   "metadata": {
    "papermill": {
     "duration": 0.030678,
     "end_time": "2023-03-07T07:11:28.306817",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.276139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Fixing some data types for easier handling later on - some algorithms better deal with float (continuous) values rather than discrete integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5cfa2",
   "metadata": {
    "papermill": {
     "duration": 0.040915,
     "end_time": "2023-03-07T07:11:28.450825",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.409910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Sex']=df['Sex'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9852f25a-2f26-4988-9481-8dc18f1efcd0",
   "metadata": {
    "papermill": {
     "duration": 0.030686,
     "end_time": "2023-03-07T07:11:28.093363",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.062677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Again, use ```info()``` to see how the label encoding has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28e422",
   "metadata": {
    "papermill": {
     "duration": 0.048409,
     "end_time": "2023-03-07T07:11:28.529467",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.481058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66c268cc-fb6b-4075-b8f2-3d9c1e158f0b",
   "metadata": {
    "papermill": {
     "duration": 0.030686,
     "end_time": "2023-03-07T07:11:28.093363",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.062677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.4.3. Final prep\n",
    "**TASK:** Make a list of feature (column) names that we can use later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba2403",
   "metadata": {
    "papermill": {
     "duration": 0.030045,
     "end_time": "2023-03-07T07:11:28.590815",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.560770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8946fb06",
   "metadata": {
    "papermill": {
     "duration": 0.03152,
     "end_time": "2023-03-07T07:11:28.968577",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.937057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Exploratory Data Analysis \n",
    "\n",
    "**TIP:** We have a lot to do in this notebook, and we want to focus on the regression analysis. So, try not to spend too much time on the exploratory data analysis - you can look up solutions for plotting in the solved notebook if they take too much time, just try to at least understand what the code is doing. \n",
    "\n",
    "#### 3.1. Preliminary analysis\n",
    "\n",
    "We start by looking at some summary statistics.\n",
    "\n",
    "**TASK:** Use ```describe()``` on the dataframe to get some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8424382",
   "metadata": {
    "papermill": {
     "duration": 0.073334,
     "end_time": "2023-03-07T07:11:28.756917",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.683583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80631bcd-4879-4bba-b201-f1ffb8d32032",
   "metadata": {
    "papermill": {
     "duration": 0.03152,
     "end_time": "2023-03-07T07:11:28.968577",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.937057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Let's look at the correlation between features using the ```corr()``` function on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99566ddc",
   "metadata": {
    "papermill": {
     "duration": 0.052545,
     "end_time": "2023-03-07T07:11:28.904807",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.852262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbccd1ce-8224-4b53-b610-2205092df674",
   "metadata": {
    "papermill": {
     "duration": 0.03152,
     "end_time": "2023-03-07T07:11:28.968577",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.937057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Check out the summary statistics. Can you already spot some patterns? Remember, correlation tells us about *linear* statistical dependence. Some features are highly correlated - which ones are they? Is that surprising? What could this mean for our later regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e8d4d",
   "metadata": {
    "papermill": {
     "duration": 0.033066,
     "end_time": "2023-03-07T07:11:28.821248",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.788182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2. Visual data exploration\n",
    "\n",
    "Before starting any data analysis, we should always first inspect the data by plotting it in different ways. \n",
    "\n",
    "**TASK:** As you use different ways of plotting the data, reflect on the information conveyed and which plots you find most useful and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884edf58-ca98-45df-8b4e-6546b5887dc6",
   "metadata": {
    "papermill": {
     "duration": 0.033066,
     "end_time": "2023-03-07T07:11:28.821248",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.788182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2.1. 2D Scatter plots\n",
    "\n",
    "**TASK:** Use the ```scatter()``` function from the ```plotly.express``` library to plot 'Length' vs 'Rings'. Don't forget to add a title and axis labels. Colour the dots by the 'Sex' feature. Then swap 'Length' and 'Sex' for other features. Do you see any interesting relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d28a99",
   "metadata": {
    "papermill": {
     "duration": 1.061145,
     "end_time": "2023-03-07T07:11:30.061366",
     "exception": false,
     "start_time": "2023-03-07T07:11:29.000221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x= ... , y= ..., \n",
    "                 color= ..., \n",
    "                 title= ...,\n",
    "                 labels= ...)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dfaa2-9bad-4fb1-9020-59baae2edee6",
   "metadata": {
    "papermill": {
     "duration": 0.033066,
     "end_time": "2023-03-07T07:11:28.821248",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.788182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2.2. 3D Scatter plots\n",
    "\n",
    "**TASK:** From the ```plotly.graph_objs``` library we imported earlier, use ```Figure()``` and ```Scatter3d()``` to plot 'Length', 'Diameter' and 'Height' against each other, and colour the dots by 'Rings'. Don't forget a title and axis labels. Then swap them by other features. Again, do you see any interesting relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52f3c1",
   "metadata": {
    "papermill": {
     "duration": 0.087806,
     "end_time": "2023-03-07T07:11:30.184489",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.096683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x= ... , y= ..., z= ...,\n",
    "                                   mode='markers', marker=dict(size=5, color= ..., colorscale='Viridis'))])\n",
    "fig.update_layout(title= ...,\n",
    "                  scene=dict(xaxis_title= ...,\n",
    "                             yaxis_title= ...,\n",
    "                             zaxis_title= ...))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75737c3d-4a72-429c-8f66-3690c093f66e",
   "metadata": {
    "papermill": {
     "duration": 0.033066,
     "end_time": "2023-03-07T07:11:28.821248",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.788182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2.3. Bubble plots\n",
    "\n",
    "Bubble plots are useful to visualise various variables together in 2D. They are scatter plots that have differently sized and coloured dots, where size and colour each represent different variables. So altogether, we can use a 2D bubble plot to visualise 4 different variables. \n",
    "\n",
    "**TASK:** From the ```plotly.graph_objs``` library we imported earlier, use ```Figure()``` and ```Scatter()``` to plot 'Length' and 'Diameter' and the x- and y-axes. Set the bubble size and colour to 'Whole weight'.\n",
    "Use ```update_layout``` on your figure object to add ```title, xaxis_title, yaxis_title```. Then swap around the variables to plot. Again, do you see any interesting relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f9fb9",
   "metadata": {
    "papermill": {
     "duration": 0.073354,
     "end_time": "2023-03-07T07:11:30.295551",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.222197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(#similar to above)\n",
    "\n",
    "fig.update_layout(title= ...,\n",
    "                  xaxis_title= ...,\n",
    "                  yaxis_title= ...)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4123eac-dc19-4f80-bdc8-94ae92818c77",
   "metadata": {
    "papermill": {
     "duration": 0.033066,
     "end_time": "2023-03-07T07:11:28.821248",
     "exception": false,
     "start_time": "2023-03-07T07:11:28.788182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.2.3. Violin plots\n",
    "\n",
    "Last week, we've already seen that violin plots can be useful to visualise the distributions in different categories. Here, our only categorical variable is 'Sex'.\n",
    "\n",
    "**TASK:** From the ```plotly.graph_objs``` library we imported earlier, use ```Figure()``` and ```Violin()``` to plot the Age ('Rings') distribution for each class of 'Sex'. Use ```update_layout``` on your figure object to add ```title, xaxis_title, yaxis_title```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee72c2f",
   "metadata": {
    "papermill": {
     "duration": 0.082316,
     "end_time": "2023-03-07T07:11:30.417138",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.334822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Violin(x= ..., y= ..., box_visible=True, points='all', jitter=0.05, marker=dict(size=1), line=dict(width=1), fillcolor='lightblue', opacity=0.6)])\n",
    "fig.update_layout(# similar to above)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef831f-c545-451d-932c-9a119aec0734",
   "metadata": {},
   "source": [
    "#### 3.2.4. Pairplots\n",
    "\n",
    "In the last session, we learned that pairplots can be useful to get an idea of the pairwise relations between variables.\n",
    "\n",
    "**TASK:** Use ```pairplot()``` from ```seaborn``` to plot all variables in the dataframe against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f2396-4c82-46fb-ab08-ce2d209083b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (Ignore the warning.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a44f02-c880-4c63-b3eb-ec8981b3dd97",
   "metadata": {},
   "source": [
    "#### 3.2.5. Heatmaps\n",
    "\n",
    "Earlier we computed the correlation matrix. Heatmaps are very useful tools to visualise matrices. In a heatmap, the values in a matrix are represented by colour (or heat), which can quickly give us an idea of any structures present in a matrix. \n",
    "\n",
    "**TASK:** Recomput the correlation matrix using ```corr()``` and save it in ```corr_matrix```. Then, from the ```plotly.graph_objs``` library we imported earlier, use ```Figure()``` and ```Heatmap()```, setting ```z``` to the matrix ```values```, ```x``` to its ```index.values``` and ```y``` to its ```columns.values```. Use ```update_layout()``` to add a title and axis labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e7195",
   "metadata": {
    "papermill": {
     "duration": 0.06526,
     "end_time": "2023-03-07T07:11:30.522056",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.456796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_matrix = ...\n",
    "fig = go.Figure(data=go.Heatmap(z= ..., x= ..., y= ..., colorscale='Viridis'))\n",
    "fig.update_layout(#similar to above)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc6236",
   "metadata": {
    "papermill": {
     "duration": 0.040422,
     "end_time": "2023-03-07T07:11:30.603373",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.562951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.5. Preliminary findings from our exploratory data analysis\n",
    "\n",
    "**TASK:** Reflect! What have we learned about our dataset so far? What does the correlation of the single features with age/Rings mean in terms of variation explained (think of $R^2$)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911fa12",
   "metadata": {
    "papermill": {
     "duration": 0.039911,
     "end_time": "2023-03-07T07:11:30.684604",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.644693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Model Preparation\n",
    "\n",
    "Some final steps before we start with our regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0e972",
   "metadata": {
    "papermill": {
     "duration": 0.040163,
     "end_time": "2023-03-07T07:11:30.827749",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.787586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 4.1. Separate Features and Outcomes\n",
    "\n",
    "**TASK:** Make variables ```X``` for the feature values and ```y``` for the outcomes ('Rings'). (It might be helpful to note that 'Rings' is the last column, which can be accessed with the index ```-1```.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcc983",
   "metadata": {
    "papermill": {
     "duration": 0.048805,
     "end_time": "2023-03-07T07:11:30.917183",
     "exception": false,
     "start_time": "2023-03-07T07:11:30.868378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e51bba",
   "metadata": {
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-03-07T07:11:31.184045",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.142833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 4.2. Split Data into Training and Testing\n",
    "\n",
    "Last week, we already split our dataset into training and test data. Today, we learned why we do this and how important it is to see if our trained model generalises to previously unseen data, or if it overfits the training data, i.e. too closely follows random relations in it. \n",
    "\n",
    "**TASK:** Use the function ```train_test_split()``` on ```X, y``` to create subsets ```X_train, X_test, y_train, y_test```. Split the data 80:20 between training and test sets by fixing ```test_size``` and fix the ```random_state``` to any value of your choice (for the curious: what does that mean, fixing the random state? Try to find out...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38159ff5",
   "metadata": {
    "papermill": {
     "duration": 0.050387,
     "end_time": "2023-03-07T07:11:31.276737",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.226350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c696b62-24d2-4e58-b240-52e3c7c61d39",
   "metadata": {
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-03-07T07:11:31.184045",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.142833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Ordinary linear regression\n",
    "\n",
    "Now finally, we are ready to build a regressor for our abalone dataset. We start simple, using an ordinary linear regressor. \n",
    "\n",
    "#### 5.1. Model fitting\n",
    "**TASK:** Create a model object called ```linreg``` using ```LinearRegression()``` and fit it using ```fit()``` on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ca056-e577-46df-b15d-a07a646e60c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05987828-8783-4a3f-82f3-800fe4e37342",
   "metadata": {
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-03-07T07:11:31.184045",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.142833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Familiarize yourself with the fitted model object by looking at the coefficients and the intercept that have been fit as well as other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cba0f-aad2-47b5-bf12-68dec27ae506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc01fa-b183-476e-890c-cc3d05f6251b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe92821-4e41-4955-97c6-0a586fc1c8eb",
   "metadata": {
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-03-07T07:11:31.184045",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.142833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 5.2. Model test\n",
    "\n",
    "Even if the fitted model performs well on the training data, it may not perform well on the test data. This happens when the model is overfitting random associations in the training data rather than detecting the true underlying trends that shape the relationship between features and outcomes. Let's check how the model performs on the test data. \n",
    "\n",
    "**TASK:** Use the ```predict()``` function on ```linreg``` to make predictions for the test set, storing the results in ```ypred```, and then use functions ```r2_score()``` and ```mean_absolute_error``` to check the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6218e1-c47d-4b96-8c90-3d83564a9ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb389e1-bacb-4b15-a252-6ccbf680661a",
   "metadata": {
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-03-07T07:11:31.184045",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.142833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Reflect:** Are we happy with the result? How does it compare to the variation in outcome explained by each single feature (correlation matrix)?\n",
    "\n",
    "**TASK:** Make a scatter plot of the true vs the predicted ages using ```px.scatter()```. Don't forget title and axis labels. Add a diagonal (identity) line (*tip*: you can use ```add_traces()``` to add a line plot to your scatter plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9843c2-00d8-4e57-b538-70c798a5f2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "axmin = min([min(y_test),min(ypred)])\n",
    "axmax = max([max(y_test),max(ypred)])\n",
    "fig1 = px.line(x=[axmin, axmax], y = [axmin, axmax]) # identity line\n",
    "\n",
    "fig2 = px.scatter(x = ..., y = ..., \n",
    "                  width = 600, height=600, \n",
    "                  title = ...,\n",
    "                  labels={\"x\": ...,\n",
    "                          \"y\": ...}\n",
    "                 ).add_traces(fig1.data)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4a734-d700-49db-a5ee-9fcc52464419",
   "metadata": {
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-03-07T07:11:31.184045",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.142833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Comparison of different regressors\n",
    "\n",
    "In the lecture today, we learned that there are many different regression methods, and the above linear regressor is the simplest one. In the below, we will use variations of linear regression via *Lasso* and *Ridge* regularization to see if we can improve on the ordinary regressor or gain further insights on the importance of features. Just for fun, we will also include a *Random Forest* regressor for comparison, and you can try out others from the ```sklearn``` library if you feel curious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335f6c9",
   "metadata": {
    "papermill": {
     "duration": 0.040551,
     "end_time": "2023-03-07T07:11:31.358503",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.317952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6.1. Make a comparison pipeline\n",
    "\n",
    "Below some definitions that will help us automise the comparison. \n",
    "\n",
    "**TASK:** Go through the code and check what regressors we will compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e104e",
   "metadata": {
    "papermill": {
     "duration": 0.052256,
     "end_time": "2023-03-07T07:11:31.452231",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.399975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "pipelines={\n",
    "'lasso':make_pipeline(Lasso(random_state=1234)),\n",
    "'ridge':make_pipeline(Ridge(random_state=1234)),\n",
    "'rf':make_pipeline(RandomForestRegressor(random_state=1234)),\n",
    "\n",
    "# to be tried later on:\n",
    "# 'ridge':make_pipeline(StandardScaler(), Ridge(random_state=1234)),\n",
    "\n",
    "# some additional models to try if you feel like/have time:\n",
    "# 'enet':make_pipeline(ElasticNet(random_state=1234)),\n",
    "# 'gb':make_pipeline(GradientBoostingRegressor(random_state=1234)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec25f8-11db-4f9e-9b1e-547c9489c56e",
   "metadata": {
    "papermill": {
     "duration": 0.040551,
     "end_time": "2023-03-07T07:11:31.358503",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.317952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have learned that different methods each have their hyperparameters that can be adapted to affect the performance of the model. Below we specify values for these hyperparameters to be tried in the optimisation during cross-validation later on. \n",
    "\n",
    "**TASK:** Go through the code and check what hyperparameters the different methods have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c556b",
   "metadata": {
    "papermill": {
     "duration": 0.050881,
     "end_time": "2023-03-07T07:11:31.545011",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.494130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparagrid={\n",
    "'lasso':{\n",
    "    'lasso__alpha':[0.001,0.005,0.01,0.05,0.1,0.5,0.99]\n",
    "},\n",
    "'ridge':{\n",
    "    'ridge__alpha':[0.001,0.005,0.01,0.05,0.1,0.5,0.99]\n",
    "},\n",
    "'rf':{\n",
    "'randomforestregressor__min_samples_split':[2,4,6],\n",
    "'randomforestregressor__min_samples_leaf':[1,2,3]\n",
    "},\n",
    "    \n",
    "# hyperparameter grid of the additional models:\n",
    "# 'gb':{\n",
    "#     'gradientboostingregressor__alpha':[0.001,0.005,0.01,0.05,0.1,0.5,0.99]\n",
    "# },\n",
    "\n",
    "# 'enet':{\n",
    "#     'elasticnet__alpha':[0.001,0.005,0.01,0.05,0.1,0.5,0.99]\n",
    "# }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19557167",
   "metadata": {
    "papermill": {
     "duration": 0.040564,
     "end_time": "2023-03-07T07:11:31.717001",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.676437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6.1. Fit Models\n",
    "\n",
    "We will use ```GridSearchCV()``` from the ```sklearn.model_selection``` library, which will perform cross-validation over the defined grid of hyperparameters to fit a model with optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd16494",
   "metadata": {
    "papermill": {
     "duration": 0.048769,
     "end_time": "2023-03-07T07:11:31.634680",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.585911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab1f01-660e-44fa-a42a-f4befdc2470f",
   "metadata": {
    "papermill": {
     "duration": 0.040564,
     "end_time": "2023-03-07T07:11:31.717001",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.676437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** \n",
    "1) Create an empty dictionary called ```fit_models```.\n",
    "2) Make a ```for``` loop over ```algo,pipeline in pipelines.items()```\n",
    "3) Within the loop, create a ```model``` object using ```GridSearchCV()``` on your current ```pipeline``` and ```hyperparagrid[algo]``` using 10-fold cross-validation.\n",
    "4) Still within the loop, fit ```model``` using ```fit()``` on the training data and assign the fitted model to ```fit_models[algo]```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6647085",
   "metadata": {
    "papermill": {
     "duration": 61.305824,
     "end_time": "2023-03-07T07:12:33.063603",
     "exception": false,
     "start_time": "2023-03-07T07:11:31.757779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo,pipeline in pipelines.items():\n",
    "    model = ...\n",
    "    try:\n",
    "        print('Start training for {}'.format(algo))\n",
    "        model.fit(...,...)\n",
    "        fit_models[algo] = model\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3cb10",
   "metadata": {
    "papermill": {
     "duration": 0.042429,
     "end_time": "2023-03-07T07:12:33.209964",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.167535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6.2. Model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc50c1",
   "metadata": {
    "papermill": {
     "duration": 0.043828,
     "end_time": "2023-03-07T07:12:33.299049",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.255221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we've learned today, it's essential to test your model fitted on the training data on previously unseen test data. \n",
    "\n",
    "**TASK:** Compute and compare the $R^2$ and mean absolute erros of the different models on the test set. Which one performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652c06e",
   "metadata": {
    "papermill": {
     "duration": 0.082341,
     "end_time": "2023-03-07T07:12:33.424468",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.342127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2f542b3-bd3d-4496-a32a-3509721baf39",
   "metadata": {
    "papermill": {
     "duration": 0.043828,
     "end_time": "2023-03-07T07:12:33.299049",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.255221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's check for overfitting. For that we compare the $R^2$ computed on the training and test sets. \n",
    "\n",
    "**TASK:** Compute and compare the $R^2$ of the different models on the training set and compare them to the above $R^2$ on the test set. Is any of the models overfitting the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28853dac-9036-4779-a20d-b0e8ce8797d7",
   "metadata": {
    "papermill": {
     "duration": 0.082341,
     "end_time": "2023-03-07T07:12:33.424468",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.342127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1736a3cd-3ef8-43da-914a-fa4b6c5dbef2",
   "metadata": {
    "papermill": {
     "duration": 0.043828,
     "end_time": "2023-03-07T07:12:33.299049",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.255221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** For each fitted model, plot the true observed values in the test set vs the predicted values just as you did in **§5.2**. Don't forget to add titles and axis labels, adding any information (e.g. $R^2$) that might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617a3a9-3cd3-473f-b1b5-9345f4970707",
   "metadata": {
    "papermill": {
     "duration": 0.082341,
     "end_time": "2023-03-07T07:12:33.424468",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.342127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for algo,model in fit_models.items():\n",
    "    ypred = ...\n",
    "    axmin = min([min(y_test),min(ypred)])\n",
    "    axmax = max([max(y_test),max(ypred)])\n",
    "    fig1 = px.line(x=[axmin, axmax], y = [axmin, axmax])\n",
    "    fig2 = px.scatter(#as in §5.2\n",
    "                     ).add_traces(fig1.data)\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffc569",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Reflect:** Which of the models performs best? Which model would you trust most and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d97522-d029-4e1f-8e10-9b417e4fbbe6",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6.3. Model analysis\n",
    "\n",
    "The regression methods we used in this section can give us additional information to the ordinary linear regressor we used in the previous section. Let's look at what we can learn from the different models.\n",
    "\n",
    "#### 6.3.1. The Lasso model\n",
    "\n",
    "In the lecture today, we learned that Lasso regression can help us with feature selection, as it assigns 0 to coefficients of features that don't carry sufficient information (or that don't add information as they are linearly correlated to other features). This means that their values are ignored in the predictions of the fitted Lasso model. \n",
    "\n",
    "**TASK:** Using ```plt.figure()``` make a bar plot of the coefficients. Try to order them by value using ```pd.Series(<coefficients>, features).sort_values(ascending=False)```. As always, annotate your plot with title and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3aff7-9d65-4947-8cb9-24cdc6bdf8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lasso_model = ...\n",
    "coefs_ordered = pd.Series(...).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "# make bar plot and annotate\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e01f4-3d46-4888-a1a4-e3b81b2a2a77",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Reflect what it means that the coefficients of Sex and Length are 0. We've seen earlier that Length is highly correlated with age/Rings - so why does it get assigned a 0 coefficient?\n",
    "\n",
    "- Length is highly correlated with other features that were assigned non-zero coefficients. Because of the intercorrelation of coefficients, not all of them are needed to predict the outcome. Which one of highly correlated features gets zeroed out is more or less random. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03b357-4132-4fa5-ba64-0a0fee2e9ada",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6.3.2. The Ridge model\n",
    "\n",
    "In the lecture today, we learned that Ridge regularization can help us with feature importance, as non-informative variables will have coefficients close to 0. \n",
    "\n",
    "**TASK:** Using ```plt.figure()``` make a bar plot of the coefficients. Try to order them by value using ```pd.Series(<coefficients>, features).sort_values(ascending=False)```. As always, annotate your plot with title and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7abe377-7e1b-48f8-84c3-82edc82ea8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge_model = ...\n",
    "feat_imp = # analogous to Lasso analysis\n",
    "plt.figure(figsize=(8,4))\n",
    "# make bar plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba064ba7-89e0-4401-ad8f-67f48f6ba730",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** \n",
    "1) Reflect what the importance of different features tells us. How do the coefficients compare to those of the Lasso model.\n",
    "2) To look at feature importance, we should always use scaled or normalised features, meaning that their values get rescaled so that they are all within the same range. Repeat the Ridge regression analysis (from **§6.1** up to here) using ```StandardScaler()``` in **§6.1**. How do the feature importances change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792549b-6917-4150-9401-54ab35f61a68",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6.3.3. The Random Forest model\n",
    "\n",
    "In the lecture, we haven't discussed Random Forest models in detail, but they are often a simple yet useful method for both regression and classification. The fitted model also comes with a list of feature importances. Let's look at those. \n",
    "\n",
    "**TASK:** You can access the feature importances via ```rf_model.best_estimator_.named_steps.randomforestregressor.feature_importances_```. Same as for the Ridge model, make a bar plot of the feature importances (ideally ordered) and annotate your plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd3989",
   "metadata": {
    "papermill": {
     "duration": 0.050824,
     "end_time": "2023-03-07T07:12:33.605624",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.554800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model = ...\n",
    "feat_imp_rf = ...\n",
    "plt.figure(figsize=(8,4))\n",
    "# make bar plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edbddc-4d2c-4c34-873c-a3af2037005e",
   "metadata": {
    "papermill": {
     "duration": 0.042603,
     "end_time": "2023-03-07T07:12:33.511597",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.468994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Reflect and compare the feature importances of the Random Forest model with those of the Ridge model. What are the differences, and which importances would you trust more. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a5792",
   "metadata": {
    "papermill": {
     "duration": 0.042898,
     "end_time": "2023-03-07T07:12:33.801466",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.758568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c59883",
   "metadata": {
    "papermill": {
     "duration": 0.042676,
     "end_time": "2023-03-07T07:12:33.887435",
     "exception": false,
     "start_time": "2023-03-07T07:12:33.844759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TASK:** Look back over the whole notebook - what have we learned about the abalone data and the predictability of age (in terms of number of rings)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 79.041797,
   "end_time": "2023-03-07T07:12:35.043240",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-07T07:11:16.001443",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

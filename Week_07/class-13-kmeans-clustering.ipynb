{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4"
   },
   "source": [
    "# Cluster analysis\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "Today we learned about clustering for unsupervised machine learning and the k-means algorithm in particular. For a user-specified number $k$ of clusters, k-means assigns data points to their nearest centroid, which is iteratively readjusted to the mean of each cluster and points reassigned until clusters don't change anymore (or not much anymore). \n",
    "\n",
    "\n",
    "In this notebook we will use k-means clustering to analyse the Breast Cancer Wisconsin (Diagnostic) Data Set - check out the description here: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data.\n",
    "\n",
    "The data is in fact labelled - the column ```\"diagnosis\"``` takes values 'B' (benign) and 'M' (malignant). Here, we will ignore the outcome labels at first, perform clustering and then check if the assigned clusters make any sense, i.e. coincide with the observed outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4",
    "tags": []
   },
   "source": [
    "## 2. Import and data prep\n",
    "### 2.1. Importing Dependencies\n",
    "\n",
    "As usual, we start by importing libraries we will use later on. Throughout the notebook, if any functions are unclear, try googling the library and function to familiarize yourself with the functions and their in- and outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8458c8e-b233-49d5-9770-694bece81293",
    "_execution_state": "idle",
    "_uuid": "47783dbf4676f1bed198dbe3768f6ba487fbe975"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from subprocess import check_output\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, silhouette_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4"
   },
   "source": [
    "### 2.2. Load data\n",
    "\n",
    "**TASK:** Load the file ```breast-cancer-wisconsin.csv``` located in the same directory as this notebook using ```read_csv()``` from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4"
   },
   "source": [
    "### 2.3. Data summary\n",
    "\n",
    "As usual, we start by having a peak at the data. \n",
    "\n",
    "**TASK:** Use ```head()```, ```describe()``` and ```info()``` on the dataframe to get a first idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f88dc98-b91a-4574-b182-069395a1a5f0",
    "_execution_state": "idle",
    "_uuid": "4e309f19617f2bcef1595de0d6df5d3bc7460844"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f88dc98-b91a-4574-b182-069395a1a5f0",
    "_execution_state": "idle",
    "_uuid": "4e309f19617f2bcef1595de0d6df5d3bc7460844"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4"
   },
   "source": [
    "**TASK:** Check how many data points are classed as benign/malignant using ```groupby()``` and ```size()```, just as we did in the kNN notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11b4940c-edea-4a20-998c-1cb991364255",
    "_execution_state": "idle",
    "_uuid": "6825ae38559605f4433cb03cb41f2f0e32844de4"
   },
   "source": [
    "**TASK:** Check for missing values (NaN = not a number) using ```isna()``` on the dataframe, just as we did in the regression notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f88dc98-b91a-4574-b182-069395a1a5f0",
    "_execution_state": "idle",
    "_uuid": "4e309f19617f2bcef1595de0d6df5d3bc7460844"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** We don't need the first and last column ('id', 'Unnamed: 32') - drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869"
   },
   "outputs": [],
   "source": [
    "# Cleaning and modifying the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Assign the number of data points and columns to variables ```ndat, nvar``` using ```shape```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869"
   },
   "outputs": [],
   "source": [
    "ndat, nvar = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we map the diagnostic values to binary values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869"
   },
   "outputs": [],
   "source": [
    "# Mapping Benign to 0 and Malignant to 1 \n",
    "data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "**TASK:** In the past two sessions, we've used a variety of plotting tools. Think which ones you found most useful and try them on this dataset. Keep in mind though, that this dataset has a lot more data columns than those we've used in the previos two sessions. This might make it a bit more cumbersome to look at all variables at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect:** Do you think the data look well separable, i.e. a clustering method would be able to find clusters that roughly coincide with the diagnotic outcomes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Compute and plot the correlation matrix, just as we did in the regression notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_matrix = ...\n",
    "\n",
    "fig = ...\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Data preparation\n",
    "### 4.1. Data scaling\n",
    "\n",
    "Data scaling is important, as we're assigning clusters based on Euclidean distance. This means that for all data variables to get the same importance, they need to range on the same scale. \n",
    "\n",
    "We scale the data using ```scale()``` from sklearn ```preprocessing``` library we imported at the beginning. We don't need to rescale the ```\"diagnosis\"``` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869"
   },
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "datas = pd.DataFrame(preprocessing.scale(data.iloc[:,1:nvar+1]))\n",
    "datas.columns = list(data.iloc[:,1:nvar+1].columns)\n",
    "datas['diagnosis'] = data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Assign the scaled data to a variable ```X```, which we will use for the cluster analysis. Don't forget to drop diagnosis, which should not be considered in the clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869"
   },
   "outputs": [],
   "source": [
    "# Creating the high dimensional feature space X\n",
    "data_drop = ...\n",
    "X = ...\n",
    "# you might want to check out X now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Dimensionality reduction for later visualisation\n",
    "\n",
    "We have 30 variables, and it is hard to visualize results in 30D. Here we use dimensionality reduction, to project data down to 2D and visualize clustering results later on. We will learn more about dimensionality reduction in the next lecture. Just for fun, we will use two different techniques to see how the final visualization can differ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Principle component analysis\n",
    "\n",
    "Principal component analysis (PCA) is a popular technique for analyzing large datasets containing a high number of dimensions/features per observation, increasing the interpretability of data while preserving the maximum amount of information, and enabling the visualization of multidimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca=PCA()\n",
    "#Fit PCA to the dataset (only variables, excluding class)\n",
    "pca.fit(data_drop)\n",
    "\n",
    "# datapca is the data projected onto the principle components\n",
    "datapca = pca.transform(data_drop)\n",
    "classes = data.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. t-SNE\n",
    "\n",
    "t-distributed stochastic neighbor embedding (t-SNE) is a statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8296ef1-f658-4efa-a71a-77864d582979",
    "_execution_state": "idle",
    "_uuid": "8ea2e37ae63d8ecb4f114d437c57116a06371869"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne is the data projected onto the tsne dimensions\n",
    "tsne = TSNE(verbose=1, perplexity=40, n_iter= 4000)\n",
    "datatsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Perform k-means\n",
    "\n",
    "Finally, we can use k-means to cluster our dataset. \n",
    "\n",
    "**TASK:** Create a k-means model object called ```km``` using ```KMeans()``` (set options to: ```n_init=10, max_iter=300, tol=0.0001, verbose=0, random_state=0, copy_x=True```) and then fit it using ```fit_predict()``` on the data vector ```X```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1f90b94-4fe9-4edb-b49f-a4178f9438fd",
    "_execution_state": "idle",
    "_uuid": "270739d4c7599912717e58f45e14a0ba96c38963"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(...)\n",
    "kY = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Cluster visualisation\n",
    "\n",
    "Earlier in **§4** we computed the principle components and t-SNE projections. Use them now to visualize your clustering results in 2D. Which 2D projection do you find more useful?\n",
    "\n",
    "**TASK:** Make two scatter plots using the first two principle components (```datapca```) computed in **§4.2.1** as axes. In the first scatter plot colour the data points by their cluster labels ```kY```, and in the second plot, for comparison, use the actual classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1f90b94-4fe9-4edb-b49f-a4178f9438fd",
    "_execution_state": "idle",
    "_uuid": "270739d4c7599912717e58f45e14a0ba96c38963"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Now make the same scatter plots, using the t-SNE projections (```datatsne```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1f90b94-4fe9-4edb-b49f-a4178f9438fd",
    "_execution_state": "idle",
    "_uuid": "270739d4c7599912717e58f45e14a0ba96c38963"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect:** From the above plots, do you think the clustering did a good job?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Evaluation\n",
    "\n",
    "Since we know the actual outcomes, we can compare them to the assigned clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:** Compute the confusion matrix (like we did for kNN) and plot a heatmap of it (like we did in the regression notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The clustering doesn't know which class is which, so we might need to invert cluster indices (swap 0 and 1)\n",
    "# kY = [int(x) for x in kY==0]\n",
    "\n",
    "cm = ...\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "accuracy = accuracy_score(data.diagnosis, kY)\n",
    "print('\\n Clusters coincide with diagnosis with ' + str(round(accuracy*100, 2)) + '% accuracy.')\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Finding a good $k$\n",
    "\n",
    "Above, we used $k=2$, because we knew that there are two different diagnostic outcomes. In principle, however, when faced with a clustering problem, we don't *a priori* know the number of clusters. In the lecture, we learned that we can use an elbow plot to find the best $k$. \n",
    "\n",
    "**TASK:** Within a ```for``` loop, fit a k-means model for $k=1,...,10$ and compute the total within-cluster variation (**tip:** it can be accessed via the ```inertia_``` property of the fitted model). Store the within-cluster variation in an array and plot it against $k$ to get the elbow plot. What does the plot say about the optimal value of $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, ...)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(...)\n",
    "\n",
    "plt.figure()\n",
    "...\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
